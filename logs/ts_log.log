2023-02-08T14:59:46,667 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-02-08T14:59:46,667 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-02-08T14:59:46,724 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.0
TS Home: /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages
Current directory: /home/eirini/PycharmProjects/Intent_Classification_AIDL
Temp directory: /tmp
Metrics config path: /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 3462 M
Python executable: /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python
Config file: ./deployment/config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /home/eirini/PycharmProjects/Intent_Classification_AIDL/deployment/model-store
Initial Models: roberta_intent=roberta_intent.mar
Log dir: /home/eirini/PycharmProjects/Intent_Classification_AIDL/logs
Metrics dir: /home/eirini/PycharmProjects/Intent_Classification_AIDL/logs
Netty threads: 1
Netty client threads: 1
Default workers per model: 2
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: true
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/eirini/PycharmProjects/Intent_Classification_AIDL/deployment/model-store
Model config: N/A
2023-02-08T14:59:46,724 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.0
TS Home: /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages
Current directory: /home/eirini/PycharmProjects/Intent_Classification_AIDL
Temp directory: /tmp
Metrics config path: /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 3462 M
Python executable: /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python
Config file: ./deployment/config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /home/eirini/PycharmProjects/Intent_Classification_AIDL/deployment/model-store
Initial Models: roberta_intent=roberta_intent.mar
Log dir: /home/eirini/PycharmProjects/Intent_Classification_AIDL/logs
Metrics dir: /home/eirini/PycharmProjects/Intent_Classification_AIDL/logs
Netty threads: 1
Netty client threads: 1
Default workers per model: 2
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: true
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/eirini/PycharmProjects/Intent_Classification_AIDL/deployment/model-store
Model config: N/A
2023-02-08T14:59:46,730 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-02-08T14:59:46,730 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-02-08T14:59:46,749 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: roberta_intent.mar
2023-02-08T14:59:46,749 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: roberta_intent.mar
2023-02-08T14:59:50,592 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model roberta_intent
2023-02-08T14:59:50,592 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model roberta_intent
2023-02-08T14:59:50,592 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model roberta_intent
2023-02-08T14:59:50,592 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model roberta_intent
2023-02-08T14:59:50,592 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model roberta_intent loaded.
2023-02-08T14:59:50,592 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model roberta_intent loaded.
2023-02-08T14:59:50,592 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: roberta_intent, count: 2
2023-02-08T14:59:50,592 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: roberta_intent, count: 2
2023-02-08T14:59:50,602 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T14:59:50,601 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T14:59:50,602 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T14:59:50,601 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T14:59:50,603 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-02-08T14:59:50,603 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-02-08T14:59:50,664 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-02-08T14:59:50,664 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-02-08T14:59:50,664 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-02-08T14:59:50,664 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-02-08T14:59:50,666 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-02-08T14:59:50,666 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-02-08T14:59:50,666 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-02-08T14:59:50,666 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-02-08T14:59:50,667 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-02-08T14:59:50,667 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-02-08T14:59:50,852 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-02-08T14:59:50,852 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-02-08T14:59:50,889 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:eirini-IdeaPad-3-15ALC6,timestamp:1675861190
2023-02-08T14:59:50,890 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:263.68565368652344|#Level:Host|#hostname:eirini-IdeaPad-3-15ALC6,timestamp:1675861190
2023-02-08T14:59:50,891 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:180.3663787841797|#Level:Host|#hostname:eirini-IdeaPad-3-15ALC6,timestamp:1675861190
2023-02-08T14:59:50,891 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:40.6|#Level:Host|#hostname:eirini-IdeaPad-3-15ALC6,timestamp:1675861190
2023-02-08T14:59:50,891 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:6187.22265625|#Level:Host|#hostname:eirini-IdeaPad-3-15ALC6,timestamp:1675861190
2023-02-08T14:59:50,891 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:7243.62890625|#Level:Host|#hostname:eirini-IdeaPad-3-15ALC6,timestamp:1675861190
2023-02-08T14:59:50,891 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:55.3|#Level:Host|#hostname:eirini-IdeaPad-3-15ALC6,timestamp:1675861190
2023-02-08T14:59:51,473 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-02-08T14:59:51,475 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Successfully loaded /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2023-02-08T14:59:51,476 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - [PID]594944
2023-02-08T14:59:51,476 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Torch worker started.
2023-02-08T14:59:51,476 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2023-02-08T14:59:51,476 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change null -> WORKER_STARTED
2023-02-08T14:59:51,476 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change null -> WORKER_STARTED
2023-02-08T14:59:51,483 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-02-08T14:59:51,483 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-02-08T14:59:51,482 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2023-02-08T14:59:51,487 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Successfully loaded /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2023-02-08T14:59:51,487 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - [PID]594945
2023-02-08T14:59:51,488 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change null -> WORKER_STARTED
2023-02-08T14:59:51,488 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change null -> WORKER_STARTED
2023-02-08T14:59:51,488 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Torch worker started.
2023-02-08T14:59:51,488 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2023-02-08T14:59:51,488 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2023-02-08T14:59:51,488 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2023-02-08T14:59:51,491 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-02-08T14:59:51,491 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2023-02-08T14:59:51,494 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861191494
2023-02-08T14:59:51,494 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861191494
2023-02-08T14:59:51,494 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861191494
2023-02-08T14:59:51,494 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861191494
2023-02-08T14:59:51,522 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - model_name: roberta_intent, batchSize: 1
2023-02-08T14:59:51,523 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - model_name: roberta_intent, batchSize: 1
2023-02-08T14:59:51,687 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 14:59:51.687021: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
2023-02-08T14:59:51,687 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 14:59:51.687172: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
2023-02-08T14:59:51,688 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-08T14:59:51,688 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-08T14:59:52,303 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 14:59:52.302984: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-08T14:59:52,303 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 14:59:52.303045: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-08T14:59:52,303 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 14:59:52.303053: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-02-08T14:59:52,304 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 14:59:52.304000: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-08T14:59:52,304 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 14:59:52.304045: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-08T14:59:52,305 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 14:59:52.304051: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-02-08T14:59:53,500 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package wordnet to /home/eirini/nltk_data...
2023-02-08T14:59:53,500 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package wordnet to /home/eirini/nltk_data...
2023-02-08T14:59:53,514 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package wordnet is already up-to-date!
2023-02-08T14:59:53,514 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package wordnet is already up-to-date!
2023-02-08T14:59:53,515 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package omw-1.4 to /home/eirini/nltk_data...
2023-02-08T14:59:53,515 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package omw-1.4 to /home/eirini/nltk_data...
2023-02-08T14:59:53,550 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package omw-1.4 is already up-to-date!
2023-02-08T14:59:53,550 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package omw-1.4 is already up-to-date!
2023-02-08T14:59:53,551 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Backend worker process died.
2023-02-08T14:59:53,551 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Backend worker process died.
2023-02-08T14:59:53,551 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T14:59:53,551 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T14:59:53,552 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 100, in load
2023-02-08T14:59:53,552 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 100, in load
2023-02-08T14:59:53,552 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-02-08T14:59:53,552 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-02-08T14:59:53,552 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-02-08T14:59:53,552 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-02-08T14:59:53,552 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-02-08T14:59:53,552 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-02-08T14:59:53,552 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T14:59:53,552 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T14:59:53,552 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T14:59:53,552 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T14:59:53,552 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T14:59:53,552 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T14:59:53,552 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T14:59:53,552 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T14:59:53,553 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2023-02-08T14:59:53,553 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2023-02-08T14:59:53,553 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2023-02-08T14:59:53,553 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2023-02-08T14:59:53,553 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2023-02-08T14:59:53,553 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2023-02-08T14:59:53,553 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T14:59:53,553 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T14:59:53,553 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/handler.py", line 14, in <module>
2023-02-08T14:59:53,553 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/handler.py", line 14, in <module>
2023-02-08T14:59:53,553 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     from preprocessing_tools import PreProcessText
2023-02-08T14:59:53,553 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     from preprocessing_tools import PreProcessText
2023-02-08T14:59:53,553 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/preprocessing_tools.py", line 11, in <module>
2023-02-08T14:59:53,553 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/preprocessing_tools.py", line 11, in <module>
2023-02-08T14:59:53,553 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     from sklearn.preprocessing import OneHotEncoder
2023-02-08T14:59:53,553 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     from sklearn.preprocessing import OneHotEncoder
2023-02-08T14:59:53,553 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'sklearn'
2023-02-08T14:59:53,554 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'sklearn'
2023-02-08T14:59:53,554 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T14:59:53,554 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T14:59:53,554 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-02-08T14:59:53,554 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-02-08T14:59:53,554 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T14:59:53,554 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T14:59:53,554 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T14:59:53,554 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T14:59:53,554 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-02-08T14:59:53,554 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-02-08T14:59:53,554 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     worker.run_server()
2023-02-08T14:59:53,554 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     worker.run_server()
2023-02-08T14:59:53,554 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-02-08T14:59:53,554 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-02-08T14:59:53,554 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-02-08T14:59:53,555 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-02-08T14:59:53,555 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-02-08T14:59:53,555 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-02-08T14:59:53,555 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-02-08T14:59:53,555 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-02-08T14:59:53,555 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-02-08T14:59:53,555 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-02-08T14:59:53,555 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 102, in load
2023-02-08T14:59:53,555 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-02-08T14:59:53,555 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2023-02-08T14:59:53,555 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-02-08T14:59:53,555 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 151, in _load_default_handler
2023-02-08T14:59:53,555 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2023-02-08T14:59:53,555 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 102, in load
2023-02-08T14:59:53,556 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2023-02-08T14:59:53,556 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T14:59:53,556 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 151, in _load_default_handler
2023-02-08T14:59:53,556 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T14:59:53,556 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2023-02-08T14:59:53,556 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T14:59:53,556 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T14:59:53,556 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T14:59:53,556 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T14:59:53,556 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2023-02-08T14:59:53,556 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T14:59:53,556 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T14:59:53,556 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T14:59:53,556 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T14:59:53,556 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2023-02-08T14:59:53,556 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T14:59:53,557 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T14:59:53,557 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2023-02-08T14:59:53,557 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T14:59:53,557 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handler'
2023-02-08T14:59:53,557 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T14:59:53,557 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2023-02-08T14:59:53,557 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handler'
2023-02-08T14:59:53,832 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-02-08T14:59:53,832 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-02-08T14:59:53,833 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T14:59:53,833 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T14:59:53,837 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2023-02-08T14:59:53,837 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2023-02-08T14:59:53,838 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T14:59:53,838 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T14:59:53,833 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T14:59:53,838 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T14:59:53,838 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T14:59:53,833 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T14:59:53,847 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T14:59:53,847 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T14:59:53,847 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T14:59:53,847 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T14:59:53,847 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T14:59:53,847 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T14:59:53,847 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T14:59:53,847 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T14:59:53,848 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stderr
2023-02-08T14:59:53,848 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stderr
2023-02-08T14:59:53,848 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stderr
2023-02-08T14:59:53,848 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stdout
2023-02-08T14:59:53,848 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stdout
2023-02-08T14:59:53,848 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stderr
2023-02-08T14:59:53,848 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stdout
2023-02-08T14:59:53,848 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stdout
2023-02-08T14:59:53,848 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2023-02-08T14:59:53,848 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-02-08T14:59:53,848 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2023-02-08T14:59:53,848 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-02-08T14:59:53,873 [INFO ] W-9001-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stderr
2023-02-08T14:59:53,873 [INFO ] W-9001-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stdout
2023-02-08T14:59:53,873 [INFO ] W-9001-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stderr
2023-02-08T14:59:53,873 [INFO ] W-9001-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stdout
2023-02-08T14:59:53,874 [INFO ] W-9000-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stderr
2023-02-08T14:59:53,874 [INFO ] W-9000-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stdout
2023-02-08T14:59:53,874 [INFO ] W-9000-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stderr
2023-02-08T14:59:53,874 [INFO ] W-9000-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stdout
2023-02-08T14:59:54,850 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T14:59:54,850 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T14:59:54,850 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T14:59:54,850 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T14:59:55,637 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-02-08T14:59:55,640 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Successfully loaded /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2023-02-08T14:59:55,640 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - [PID]595037
2023-02-08T14:59:55,640 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Torch worker started.
2023-02-08T14:59:55,640 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T14:59:55,640 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2023-02-08T14:59:55,640 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T14:59:55,641 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-02-08T14:59:55,641 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-02-08T14:59:55,642 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861195642
2023-02-08T14:59:55,642 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-02-08T14:59:55,642 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861195642
2023-02-08T14:59:55,643 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - model_name: roberta_intent, batchSize: 1
2023-02-08T14:59:55,676 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2023-02-08T14:59:55,680 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Successfully loaded /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2023-02-08T14:59:55,680 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - [PID]595036
2023-02-08T14:59:55,680 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Torch worker started.
2023-02-08T14:59:55,680 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T14:59:55,680 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T14:59:55,680 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2023-02-08T14:59:55,681 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2023-02-08T14:59:55,681 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2023-02-08T14:59:55,682 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861195682
2023-02-08T14:59:55,682 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861195682
2023-02-08T14:59:55,682 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2023-02-08T14:59:55,683 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - model_name: roberta_intent, batchSize: 1
2023-02-08T14:59:55,810 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 14:59:55.810720: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
2023-02-08T14:59:55,811 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-08T14:59:55,846 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 14:59:55.845980: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
2023-02-08T14:59:55,846 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-08T14:59:56,421 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 14:59:56.421183: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-08T14:59:56,421 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 14:59:56.421228: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-08T14:59:56,422 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 14:59:56.421233: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-02-08T14:59:56,454 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 14:59:56.454259: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-08T14:59:56,454 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 14:59:56.454307: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-08T14:59:56,454 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 14:59:56.454313: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-02-08T14:59:57,564 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package wordnet to /home/eirini/nltk_data...
2023-02-08T14:59:57,579 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package wordnet is already up-to-date!
2023-02-08T14:59:57,580 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package omw-1.4 to /home/eirini/nltk_data...
2023-02-08T14:59:57,584 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package wordnet to /home/eirini/nltk_data...
2023-02-08T14:59:57,599 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package wordnet is already up-to-date!
2023-02-08T14:59:57,599 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package omw-1.4 to /home/eirini/nltk_data...
2023-02-08T14:59:57,616 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package omw-1.4 is already up-to-date!
2023-02-08T14:59:57,617 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Backend worker process died.
2023-02-08T14:59:57,617 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T14:59:57,617 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 100, in load
2023-02-08T14:59:57,617 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-02-08T14:59:57,617 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-02-08T14:59:57,618 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-02-08T14:59:57,618 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T14:59:57,618 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T14:59:57,618 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T14:59:57,618 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T14:59:57,618 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2023-02-08T14:59:57,618 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2023-02-08T14:59:57,618 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2023-02-08T14:59:57,618 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T14:59:57,618 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/handler.py", line 14, in <module>
2023-02-08T14:59:57,618 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     from preprocessing_tools import PreProcessText
2023-02-08T14:59:57,618 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/preprocessing_tools.py", line 11, in <module>
2023-02-08T14:59:57,618 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     from sklearn.preprocessing import OneHotEncoder
2023-02-08T14:59:57,618 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'sklearn'
2023-02-08T14:59:57,618 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T14:59:57,618 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-02-08T14:59:57,618 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T14:59:57,619 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T14:59:57,619 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-02-08T14:59:57,619 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     worker.run_server()
2023-02-08T14:59:57,619 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-02-08T14:59:57,619 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-02-08T14:59:57,619 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-02-08T14:59:57,619 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-02-08T14:59:57,619 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-02-08T14:59:57,619 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-02-08T14:59:57,619 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 102, in load
2023-02-08T14:59:57,619 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2023-02-08T14:59:57,619 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 151, in _load_default_handler
2023-02-08T14:59:57,619 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2023-02-08T14:59:57,619 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T14:59:57,620 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T14:59:57,620 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T14:59:57,620 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T14:59:57,620 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2023-02-08T14:59:57,620 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T14:59:57,620 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T14:59:57,620 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T14:59:57,620 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2023-02-08T14:59:57,620 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handler'
2023-02-08T14:59:57,636 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package omw-1.4 is already up-to-date!
2023-02-08T14:59:57,636 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Backend worker process died.
2023-02-08T14:59:57,637 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T14:59:57,637 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 100, in load
2023-02-08T14:59:57,637 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-02-08T14:59:57,637 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-02-08T14:59:57,637 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-02-08T14:59:57,637 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T14:59:57,637 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T14:59:57,637 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T14:59:57,637 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T14:59:57,637 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2023-02-08T14:59:57,637 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2023-02-08T14:59:57,637 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2023-02-08T14:59:57,637 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T14:59:57,637 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/handler.py", line 14, in <module>
2023-02-08T14:59:57,637 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     from preprocessing_tools import PreProcessText
2023-02-08T14:59:57,637 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/preprocessing_tools.py", line 11, in <module>
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     from sklearn.preprocessing import OneHotEncoder
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'sklearn'
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     worker.run_server()
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 102, in load
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 151, in _load_default_handler
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2023-02-08T14:59:57,638 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T14:59:57,639 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T14:59:57,639 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T14:59:57,639 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2023-02-08T14:59:57,639 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handler'
2023-02-08T14:59:57,897 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-02-08T14:59:57,897 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-02-08T14:59:57,898 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T14:59:57,898 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T14:59:57,898 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T14:59:57,898 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T14:59:57,898 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T14:59:57,898 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T14:59:57,899 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T14:59:57,899 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T14:59:57,899 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stderr
2023-02-08T14:59:57,899 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stderr
2023-02-08T14:59:57,899 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stdout
2023-02-08T14:59:57,899 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stdout
2023-02-08T14:59:57,899 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-02-08T14:59:57,899 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-02-08T14:59:57,913 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2023-02-08T14:59:57,913 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2023-02-08T14:59:57,913 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T14:59:57,913 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T14:59:57,914 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T14:59:57,914 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T14:59:57,914 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T14:59:57,914 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T14:59:57,914 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T14:59:57,914 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T14:59:57,915 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stderr
2023-02-08T14:59:57,915 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stderr
2023-02-08T14:59:57,915 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stdout
2023-02-08T14:59:57,915 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stdout
2023-02-08T14:59:57,915 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2023-02-08T14:59:57,915 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2023-02-08T14:59:57,922 [INFO ] W-9000-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stdout
2023-02-08T14:59:57,922 [INFO ] W-9000-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stderr
2023-02-08T14:59:57,922 [INFO ] W-9000-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stdout
2023-02-08T14:59:57,922 [INFO ] W-9000-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stderr
2023-02-08T14:59:57,940 [INFO ] W-9001-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stdout
2023-02-08T14:59:57,940 [INFO ] W-9001-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stderr
2023-02-08T14:59:57,940 [INFO ] W-9001-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stdout
2023-02-08T14:59:57,940 [INFO ] W-9001-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stderr
2023-02-08T14:59:58,900 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T14:59:58,900 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T14:59:58,915 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T14:59:58,915 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T14:59:59,677 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2023-02-08T14:59:59,681 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Successfully loaded /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2023-02-08T14:59:59,681 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - [PID]595107
2023-02-08T14:59:59,681 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Torch worker started.
2023-02-08T14:59:59,681 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2023-02-08T14:59:59,681 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T14:59:59,681 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T14:59:59,681 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2023-02-08T14:59:59,681 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2023-02-08T14:59:59,682 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861199682
2023-02-08T14:59:59,682 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861199682
2023-02-08T14:59:59,682 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2023-02-08T14:59:59,683 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - model_name: roberta_intent, batchSize: 1
2023-02-08T14:59:59,734 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-02-08T14:59:59,737 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Successfully loaded /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2023-02-08T14:59:59,737 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - [PID]595104
2023-02-08T14:59:59,737 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Torch worker started.
2023-02-08T14:59:59,738 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T14:59:59,738 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T14:59:59,738 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2023-02-08T14:59:59,738 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-02-08T14:59:59,738 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-02-08T14:59:59,739 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861199739
2023-02-08T14:59:59,739 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861199739
2023-02-08T14:59:59,739 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-02-08T14:59:59,740 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - model_name: roberta_intent, batchSize: 1
2023-02-08T14:59:59,850 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 14:59:59.850397: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
2023-02-08T14:59:59,851 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-08T14:59:59,904 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 14:59:59.903584: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
2023-02-08T14:59:59,904 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-08T15:00:00,465 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:00.465423: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:00,466 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:00.465469: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:00,466 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:00.465475: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-02-08T15:00:00,509 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:00.509255: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:00,509 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:00.509644: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:00,509 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:00.509755: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-02-08T15:00:01,666 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package wordnet to /home/eirini/nltk_data...
2023-02-08T15:00:01,676 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package wordnet to /home/eirini/nltk_data...
2023-02-08T15:00:01,680 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package wordnet is already up-to-date!
2023-02-08T15:00:01,680 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package omw-1.4 to /home/eirini/nltk_data...
2023-02-08T15:00:01,690 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package wordnet is already up-to-date!
2023-02-08T15:00:01,691 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package omw-1.4 to /home/eirini/nltk_data...
2023-02-08T15:00:01,717 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package omw-1.4 is already up-to-date!
2023-02-08T15:00:01,717 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Backend worker process died.
2023-02-08T15:00:01,717 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:01,717 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 100, in load
2023-02-08T15:00:01,717 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-02-08T15:00:01,717 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/handler.py", line 14, in <module>
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     from preprocessing_tools import PreProcessText
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/preprocessing_tools.py", line 11, in <module>
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     from sklearn.preprocessing import OneHotEncoder
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'sklearn'
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     worker.run_server()
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 102, in load
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 151, in _load_default_handler
2023-02-08T15:00:01,718 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2023-02-08T15:00:01,719 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:01,719 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:01,719 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:01,719 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:01,719 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2023-02-08T15:00:01,719 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:01,719 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:01,719 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:01,719 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2023-02-08T15:00:01,719 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handler'
2023-02-08T15:00:01,728 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package omw-1.4 is already up-to-date!
2023-02-08T15:00:01,728 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Backend worker process died.
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 100, in load
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/handler.py", line 14, in <module>
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     from preprocessing_tools import PreProcessText
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/preprocessing_tools.py", line 11, in <module>
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     from sklearn.preprocessing import OneHotEncoder
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'sklearn'
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     worker.run_server()
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 102, in load
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 151, in _load_default_handler
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:01,729 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:01,730 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:01,730 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2023-02-08T15:00:01,730 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:01,730 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:01,730 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:01,730 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2023-02-08T15:00:01,730 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handler'
2023-02-08T15:00:01,995 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:01,995 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:01,996 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:01,996 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:01,996 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:01,996 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:01,996 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:01,996 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:01,996 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:01,996 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:01,997 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:01,997 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:01,997 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:01,997 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:01,997 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2023-02-08T15:00:01,997 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2023-02-08T15:00:02,002 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:02,002 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:02,002 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:02,002 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:02,002 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:02,002 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:02,002 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:02,002 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:02,002 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:02,002 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:02,003 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:02,003 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:02,003 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:02,003 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:02,003 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2023-02-08T15:00:02,003 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2023-02-08T15:00:02,022 [INFO ] W-9001-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:02,022 [INFO ] W-9001-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:02,022 [INFO ] W-9001-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:02,022 [INFO ] W-9001-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:02,030 [INFO ] W-9000-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:02,030 [INFO ] W-9000-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:02,030 [INFO ] W-9000-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:02,030 [INFO ] W-9000-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:03,997 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:00:03,997 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:00:04,004 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:00:04,004 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:00:04,761 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2023-02-08T15:00:04,765 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Successfully loaded /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2023-02-08T15:00:04,765 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - [PID]595262
2023-02-08T15:00:04,765 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Torch worker started.
2023-02-08T15:00:04,765 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2023-02-08T15:00:04,765 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:00:04,765 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:00:04,765 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2023-02-08T15:00:04,765 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2023-02-08T15:00:04,766 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2023-02-08T15:00:04,767 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861204767
2023-02-08T15:00:04,767 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861204767
2023-02-08T15:00:04,767 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - model_name: roberta_intent, batchSize: 1
2023-02-08T15:00:04,812 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-02-08T15:00:04,816 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Successfully loaded /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2023-02-08T15:00:04,816 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - [PID]595265
2023-02-08T15:00:04,816 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Torch worker started.
2023-02-08T15:00:04,817 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2023-02-08T15:00:04,817 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:00:04,817 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:00:04,817 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-02-08T15:00:04,817 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-02-08T15:00:04,818 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861204818
2023-02-08T15:00:04,818 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861204818
2023-02-08T15:00:04,818 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-02-08T15:00:04,818 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - model_name: roberta_intent, batchSize: 1
2023-02-08T15:00:04,931 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:04.930808: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
2023-02-08T15:00:04,931 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-08T15:00:04,979 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:04.978742: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
2023-02-08T15:00:04,979 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-08T15:00:05,545 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:05.545694: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:05,546 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:05.545741: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:05,546 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:05.545746: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-02-08T15:00:05,584 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:05.583994: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:05,584 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:05.584328: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:05,584 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:05.584404: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-02-08T15:00:06,695 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package wordnet to /home/eirini/nltk_data...
2023-02-08T15:00:06,710 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package wordnet is already up-to-date!
2023-02-08T15:00:06,710 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package omw-1.4 to /home/eirini/nltk_data...
2023-02-08T15:00:06,716 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package wordnet to /home/eirini/nltk_data...
2023-02-08T15:00:06,731 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package wordnet is already up-to-date!
2023-02-08T15:00:06,731 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package omw-1.4 to /home/eirini/nltk_data...
2023-02-08T15:00:06,746 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package omw-1.4 is already up-to-date!
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Backend worker process died.
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 100, in load
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/handler.py", line 14, in <module>
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     from preprocessing_tools import PreProcessText
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/preprocessing_tools.py", line 11, in <module>
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     from sklearn.preprocessing import OneHotEncoder
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'sklearn'
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     worker.run_server()
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 102, in load
2023-02-08T15:00:06,747 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2023-02-08T15:00:06,748 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 151, in _load_default_handler
2023-02-08T15:00:06,748 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2023-02-08T15:00:06,748 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:06,748 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:06,748 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:06,748 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:06,748 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2023-02-08T15:00:06,748 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:06,748 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:06,748 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:06,748 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2023-02-08T15:00:06,748 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handler'
2023-02-08T15:00:06,767 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package omw-1.4 is already up-to-date!
2023-02-08T15:00:06,768 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Backend worker process died.
2023-02-08T15:00:06,768 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:06,768 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 100, in load
2023-02-08T15:00:06,768 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-02-08T15:00:06,768 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-02-08T15:00:06,768 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-02-08T15:00:06,768 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:06,768 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:06,768 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:06,768 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:06,768 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2023-02-08T15:00:06,768 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2023-02-08T15:00:06,768 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2023-02-08T15:00:06,768 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:06,768 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/handler.py", line 14, in <module>
2023-02-08T15:00:06,768 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     from preprocessing_tools import PreProcessText
2023-02-08T15:00:06,768 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/preprocessing_tools.py", line 11, in <module>
2023-02-08T15:00:06,768 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     from sklearn.preprocessing import OneHotEncoder
2023-02-08T15:00:06,768 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'sklearn'
2023-02-08T15:00:06,768 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:06,768 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     worker.run_server()
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 102, in load
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 151, in _load_default_handler
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2023-02-08T15:00:06,769 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handler'
2023-02-08T15:00:07,019 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:07,019 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:07,019 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:07,019 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:07,019 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:07,019 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:07,020 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:07,020 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:07,020 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:07,020 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:07,020 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:07,020 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:07,020 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:07,020 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:07,020 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2023-02-08T15:00:07,020 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2023-02-08T15:00:07,043 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:07,043 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:07,043 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:07,043 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:07,043 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:07,043 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:07,044 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:07,044 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:07,044 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:07,044 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:07,044 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:07,044 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:07,044 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:07,044 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:07,045 [INFO ] W-9001-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:07,045 [INFO ] W-9001-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:07,045 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2023-02-08T15:00:07,045 [INFO ] W-9001-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:07,045 [INFO ] W-9001-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:07,045 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2023-02-08T15:00:07,069 [INFO ] W-9000-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:07,069 [INFO ] W-9000-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:07,069 [INFO ] W-9000-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:07,069 [INFO ] W-9000-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:10,021 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:00:10,021 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:00:10,045 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:00:10,045 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:00:10,870 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2023-02-08T15:00:10,875 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Successfully loaded /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2023-02-08T15:00:10,875 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - [PID]595330
2023-02-08T15:00:10,875 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Torch worker started.
2023-02-08T15:00:10,875 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2023-02-08T15:00:10,875 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:00:10,875 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:00:10,875 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2023-02-08T15:00:10,875 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2023-02-08T15:00:10,876 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861210876
2023-02-08T15:00:10,876 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2023-02-08T15:00:10,876 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861210876
2023-02-08T15:00:10,877 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - model_name: roberta_intent, batchSize: 1
2023-02-08T15:00:10,917 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-02-08T15:00:10,921 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Successfully loaded /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2023-02-08T15:00:10,921 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - [PID]595333
2023-02-08T15:00:10,921 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Torch worker started.
2023-02-08T15:00:10,921 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2023-02-08T15:00:10,921 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:00:10,921 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:00:10,921 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-02-08T15:00:10,921 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-02-08T15:00:10,922 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861210922
2023-02-08T15:00:10,922 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861210922
2023-02-08T15:00:10,922 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-02-08T15:00:10,923 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - model_name: roberta_intent, batchSize: 1
2023-02-08T15:00:11,048 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:11.048266: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
2023-02-08T15:00:11,049 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-08T15:00:11,092 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:11.092423: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
2023-02-08T15:00:11,093 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-08T15:00:11,679 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:11.679571: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:11,679 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:11.679619: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:11,679 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:11.679627: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-02-08T15:00:11,706 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:11.706017: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:11,706 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:11.706064: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:11,706 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:11.706071: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-02-08T15:00:12,796 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package wordnet to /home/eirini/nltk_data...
2023-02-08T15:00:12,811 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package wordnet is already up-to-date!
2023-02-08T15:00:12,811 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package omw-1.4 to /home/eirini/nltk_data...
2023-02-08T15:00:12,818 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package wordnet to /home/eirini/nltk_data...
2023-02-08T15:00:12,833 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package wordnet is already up-to-date!
2023-02-08T15:00:12,833 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package omw-1.4 to /home/eirini/nltk_data...
2023-02-08T15:00:12,846 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package omw-1.4 is already up-to-date!
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Backend worker process died.
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 100, in load
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/handler.py", line 14, in <module>
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     from preprocessing_tools import PreProcessText
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/preprocessing_tools.py", line 11, in <module>
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     from sklearn.preprocessing import OneHotEncoder
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'sklearn'
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     worker.run_server()
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-02-08T15:00:12,847 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-02-08T15:00:12,848 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-02-08T15:00:12,848 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-02-08T15:00:12,848 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-02-08T15:00:12,848 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 102, in load
2023-02-08T15:00:12,848 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2023-02-08T15:00:12,848 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 151, in _load_default_handler
2023-02-08T15:00:12,848 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2023-02-08T15:00:12,848 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:12,848 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:12,848 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:12,848 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:12,848 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2023-02-08T15:00:12,848 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:12,848 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:12,848 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:12,848 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2023-02-08T15:00:12,848 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handler'
2023-02-08T15:00:12,869 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package omw-1.4 is already up-to-date!
2023-02-08T15:00:12,869 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Backend worker process died.
2023-02-08T15:00:12,869 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:12,869 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 100, in load
2023-02-08T15:00:12,869 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-02-08T15:00:12,869 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-02-08T15:00:12,869 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-02-08T15:00:12,869 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:12,869 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:12,869 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:12,869 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/handler.py", line 14, in <module>
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     from preprocessing_tools import PreProcessText
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/preprocessing_tools.py", line 11, in <module>
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     from sklearn.preprocessing import OneHotEncoder
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'sklearn'
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     worker.run_server()
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 102, in load
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 151, in _load_default_handler
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2023-02-08T15:00:12,870 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:12,871 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:12,871 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:12,871 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2023-02-08T15:00:12,871 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handler'
2023-02-08T15:00:13,121 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:13,121 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:13,122 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:13,122 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:13,122 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:13,122 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:13,122 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:13,122 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:13,122 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:13,122 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:13,122 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:13,122 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:13,123 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:13,123 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:13,123 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2023-02-08T15:00:13,123 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2023-02-08T15:00:13,144 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:13,144 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:13,144 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:13,144 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:13,144 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:13,144 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:13,145 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:13,145 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:13,145 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:13,145 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:13,145 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:13,145 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:13,145 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:13,145 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:13,145 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2023-02-08T15:00:13,145 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2023-02-08T15:00:13,146 [INFO ] W-9001-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:13,146 [INFO ] W-9001-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:13,146 [INFO ] W-9001-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:13,146 [INFO ] W-9001-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:13,169 [INFO ] W-9000-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:13,169 [INFO ] W-9000-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:13,169 [INFO ] W-9000-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:13,169 [INFO ] W-9000-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:18,124 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:00:18,124 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:00:18,146 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:00:18,146 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:00:18,926 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-02-08T15:00:18,929 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Successfully loaded /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2023-02-08T15:00:18,930 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - [PID]595407
2023-02-08T15:00:18,930 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Torch worker started.
2023-02-08T15:00:18,930 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2023-02-08T15:00:18,930 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:00:18,930 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:00:18,930 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-02-08T15:00:18,930 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-02-08T15:00:18,931 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861218931
2023-02-08T15:00:18,931 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-02-08T15:00:18,931 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861218931
2023-02-08T15:00:18,932 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - model_name: roberta_intent, batchSize: 1
2023-02-08T15:00:18,974 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2023-02-08T15:00:18,977 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Successfully loaded /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2023-02-08T15:00:18,977 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - [PID]595404
2023-02-08T15:00:18,977 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Torch worker started.
2023-02-08T15:00:18,977 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2023-02-08T15:00:18,978 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:00:18,978 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:00:18,978 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2023-02-08T15:00:18,978 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2023-02-08T15:00:18,978 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861218978
2023-02-08T15:00:18,979 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2023-02-08T15:00:18,978 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861218978
2023-02-08T15:00:18,979 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - model_name: roberta_intent, batchSize: 1
2023-02-08T15:00:19,102 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:19.102581: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
2023-02-08T15:00:19,103 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-08T15:00:19,149 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:19.149216: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
2023-02-08T15:00:19,149 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-08T15:00:19,711 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:19.710865: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:19,711 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:19.710912: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:19,711 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:19.710917: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-02-08T15:00:19,761 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:19.760890: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:19,761 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:19.761314: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:19,761 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:19.761445: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-02-08T15:00:20,848 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package wordnet to /home/eirini/nltk_data...
2023-02-08T15:00:20,863 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package wordnet is already up-to-date!
2023-02-08T15:00:20,863 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package omw-1.4 to /home/eirini/nltk_data...
2023-02-08T15:00:20,899 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package omw-1.4 is already up-to-date!
2023-02-08T15:00:20,899 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Backend worker process died.
2023-02-08T15:00:20,899 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 100, in load
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/handler.py", line 14, in <module>
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     from preprocessing_tools import PreProcessText
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/preprocessing_tools.py", line 11, in <module>
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     from sklearn.preprocessing import OneHotEncoder
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'sklearn'
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     worker.run_server()
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 102, in load
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 151, in _load_default_handler
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:20,900 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:20,901 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2023-02-08T15:00:20,901 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handler'
2023-02-08T15:00:20,944 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package wordnet to /home/eirini/nltk_data...
2023-02-08T15:00:20,958 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package wordnet is already up-to-date!
2023-02-08T15:00:20,958 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package omw-1.4 to /home/eirini/nltk_data...
2023-02-08T15:00:20,993 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package omw-1.4 is already up-to-date!
2023-02-08T15:00:20,993 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Backend worker process died.
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 100, in load
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/handler.py", line 14, in <module>
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     from preprocessing_tools import PreProcessText
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/preprocessing_tools.py", line 11, in <module>
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     from sklearn.preprocessing import OneHotEncoder
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'sklearn'
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     worker.run_server()
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-02-08T15:00:20,994 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-02-08T15:00:20,995 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-02-08T15:00:20,995 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-02-08T15:00:20,995 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 102, in load
2023-02-08T15:00:20,995 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2023-02-08T15:00:20,995 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 151, in _load_default_handler
2023-02-08T15:00:20,995 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2023-02-08T15:00:20,995 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:20,995 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:20,995 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:20,995 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:20,995 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2023-02-08T15:00:20,995 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:20,995 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:20,995 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:20,995 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2023-02-08T15:00:20,995 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handler'
2023-02-08T15:00:21,173 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:21,173 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:21,173 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:21,173 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:21,174 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:21,174 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:21,174 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:21,174 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:21,174 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:21,174 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:21,174 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:21,174 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:21,175 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:21,175 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:21,175 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2023-02-08T15:00:21,175 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2023-02-08T15:00:21,202 [INFO ] W-9000-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:21,202 [INFO ] W-9000-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:21,202 [INFO ] W-9000-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:21,202 [INFO ] W-9000-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:21,265 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:21,265 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:21,265 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:21,265 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:21,265 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:21,265 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:21,266 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:21,266 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:21,266 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:21,266 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:21,266 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:21,266 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:21,266 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:21,266 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:21,266 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2023-02-08T15:00:21,266 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2023-02-08T15:00:21,289 [INFO ] W-9001-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:21,289 [INFO ] W-9001-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:21,289 [INFO ] W-9001-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:21,289 [INFO ] W-9001-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:29,176 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:00:29,176 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:00:29,267 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:00:29,267 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:00:30,060 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-02-08T15:00:30,064 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Successfully loaded /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2023-02-08T15:00:30,064 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - [PID]595474
2023-02-08T15:00:30,064 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Torch worker started.
2023-02-08T15:00:30,064 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2023-02-08T15:00:30,064 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:00:30,064 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:00:30,064 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-02-08T15:00:30,064 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-02-08T15:00:30,065 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861230065
2023-02-08T15:00:30,065 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861230065
2023-02-08T15:00:30,065 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-02-08T15:00:30,066 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - model_name: roberta_intent, batchSize: 1
2023-02-08T15:00:30,122 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2023-02-08T15:00:30,126 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Successfully loaded /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2023-02-08T15:00:30,126 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - [PID]595477
2023-02-08T15:00:30,126 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Torch worker started.
2023-02-08T15:00:30,126 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2023-02-08T15:00:30,126 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:00:30,126 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:00:30,127 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2023-02-08T15:00:30,127 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2023-02-08T15:00:30,128 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861230128
2023-02-08T15:00:30,128 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861230128
2023-02-08T15:00:30,128 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2023-02-08T15:00:30,128 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - model_name: roberta_intent, batchSize: 1
2023-02-08T15:00:30,229 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:30.229297: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
2023-02-08T15:00:30,230 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-08T15:00:30,290 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:30.290066: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
2023-02-08T15:00:30,290 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-08T15:00:30,832 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:30.832342: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:30,833 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:30.832396: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:30,833 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:30.832402: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-02-08T15:00:30,919 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:30.919667: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:30,920 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:30.920025: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:30,920 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:30.920132: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-02-08T15:00:32,041 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package wordnet to /home/eirini/nltk_data...
2023-02-08T15:00:32,056 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package wordnet is already up-to-date!
2023-02-08T15:00:32,056 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package omw-1.4 to /home/eirini/nltk_data...
2023-02-08T15:00:32,092 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package omw-1.4 is already up-to-date!
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Backend worker process died.
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 100, in load
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/handler.py", line 14, in <module>
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     from preprocessing_tools import PreProcessText
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/preprocessing_tools.py", line 11, in <module>
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     from sklearn.preprocessing import OneHotEncoder
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'sklearn'
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     worker.run_server()
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 102, in load
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 151, in _load_default_handler
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:32,093 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:32,094 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2023-02-08T15:00:32,094 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:32,094 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:32,094 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:32,094 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2023-02-08T15:00:32,094 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handler'
2023-02-08T15:00:32,105 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package wordnet to /home/eirini/nltk_data...
2023-02-08T15:00:32,120 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package wordnet is already up-to-date!
2023-02-08T15:00:32,120 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package omw-1.4 to /home/eirini/nltk_data...
2023-02-08T15:00:32,156 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package omw-1.4 is already up-to-date!
2023-02-08T15:00:32,157 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Backend worker process died.
2023-02-08T15:00:32,157 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:32,157 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 100, in load
2023-02-08T15:00:32,157 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-02-08T15:00:32,157 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-02-08T15:00:32,157 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/handler.py", line 14, in <module>
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     from preprocessing_tools import PreProcessText
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/preprocessing_tools.py", line 11, in <module>
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     from sklearn.preprocessing import OneHotEncoder
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'sklearn'
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     worker.run_server()
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 102, in load
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 151, in _load_default_handler
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2023-02-08T15:00:32,158 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handler'
2023-02-08T15:00:32,434 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:32,434 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:32,434 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:32,434 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:32,434 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:32,434 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:32,434 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:32,434 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:32,434 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:32,434 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:32,435 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:32,435 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:32,435 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:32,435 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:32,435 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2023-02-08T15:00:32,435 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2023-02-08T15:00:32,465 [INFO ] W-9000-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:32,465 [INFO ] W-9000-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:32,465 [INFO ] W-9000-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:32,465 [INFO ] W-9000-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:32,481 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:32,481 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:32,481 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:32,481 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:32,481 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:32,481 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:32,482 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:32,482 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:32,482 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:32,482 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:32,482 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:32,482 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:32,482 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:32,482 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:32,482 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2023-02-08T15:00:32,482 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2023-02-08T15:00:32,506 [INFO ] W-9001-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:32,506 [INFO ] W-9001-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:32,506 [INFO ] W-9001-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:32,506 [INFO ] W-9001-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:39,835 [INFO ] W-9001-roberta_intent_1.0 ACCESS_LOG - /127.0.0.1:59170 "GET /ping HTTP/1.1" 200 5
2023-02-08T15:00:39,836 [INFO ] W-9001-roberta_intent_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:eirini-IdeaPad-3-15ALC6,timestamp:1675861239
2023-02-08T15:00:45,436 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:00:45,436 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:00:45,483 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:00:45,483 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:00:46,331 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-02-08T15:00:46,334 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Successfully loaded /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2023-02-08T15:00:46,334 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - [PID]595674
2023-02-08T15:00:46,334 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Torch worker started.
2023-02-08T15:00:46,334 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2023-02-08T15:00:46,334 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:00:46,334 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:00:46,334 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-02-08T15:00:46,334 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-02-08T15:00:46,335 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861246335
2023-02-08T15:00:46,335 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-02-08T15:00:46,335 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861246335
2023-02-08T15:00:46,336 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - model_name: roberta_intent, batchSize: 1
2023-02-08T15:00:46,365 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2023-02-08T15:00:46,369 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Successfully loaded /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2023-02-08T15:00:46,370 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - [PID]595677
2023-02-08T15:00:46,370 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Torch worker started.
2023-02-08T15:00:46,370 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2023-02-08T15:00:46,370 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:00:46,370 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:00:46,370 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2023-02-08T15:00:46,370 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2023-02-08T15:00:46,372 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861246372
2023-02-08T15:00:46,372 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861246372
2023-02-08T15:00:46,372 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2023-02-08T15:00:46,372 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - model_name: roberta_intent, batchSize: 1
2023-02-08T15:00:46,509 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:46.509443: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
2023-02-08T15:00:46,510 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-08T15:00:46,542 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:46.542075: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
2023-02-08T15:00:46,542 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-08T15:00:47,128 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:47.128180: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:47,128 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:47.128226: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:47,129 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:47.128232: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-02-08T15:00:47,153 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:47.153642: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:47,153 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:47.153689: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:00:47,154 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:00:47.153695: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-02-08T15:00:48,296 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package wordnet to /home/eirini/nltk_data...
2023-02-08T15:00:48,310 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package wordnet is already up-to-date!
2023-02-08T15:00:48,310 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package omw-1.4 to /home/eirini/nltk_data...
2023-02-08T15:00:48,312 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package wordnet to /home/eirini/nltk_data...
2023-02-08T15:00:48,327 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package wordnet is already up-to-date!
2023-02-08T15:00:48,327 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package omw-1.4 to /home/eirini/nltk_data...
2023-02-08T15:00:48,346 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package omw-1.4 is already up-to-date!
2023-02-08T15:00:48,346 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Backend worker process died.
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 100, in load
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/handler.py", line 14, in <module>
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     from preprocessing_tools import PreProcessText
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/preprocessing_tools.py", line 11, in <module>
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     from sklearn.preprocessing import OneHotEncoder
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'sklearn'
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     worker.run_server()
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 102, in load
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 151, in _load_default_handler
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2023-02-08T15:00:48,347 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handler'
2023-02-08T15:00:48,364 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package omw-1.4 is already up-to-date!
2023-02-08T15:00:48,365 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Backend worker process died.
2023-02-08T15:00:48,365 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:48,365 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 100, in load
2023-02-08T15:00:48,365 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-02-08T15:00:48,365 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-02-08T15:00:48,365 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-02-08T15:00:48,365 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:48,365 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:48,365 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:48,365 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:48,365 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2023-02-08T15:00:48,365 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2023-02-08T15:00:48,365 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2023-02-08T15:00:48,365 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:48,365 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/handler.py", line 14, in <module>
2023-02-08T15:00:48,365 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     from preprocessing_tools import PreProcessText
2023-02-08T15:00:48,365 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/preprocessing_tools.py", line 11, in <module>
2023-02-08T15:00:48,365 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     from sklearn.preprocessing import OneHotEncoder
2023-02-08T15:00:48,365 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'sklearn'
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     worker.run_server()
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 102, in load
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 151, in _load_default_handler
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2023-02-08T15:00:48,366 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handler'
2023-02-08T15:00:48,639 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:48,639 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:48,639 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:48,639 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:48,639 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:48,639 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:48,639 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:48,639 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:48,639 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:48,639 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:48,639 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:48,639 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:48,639 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:48,639 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:48,639 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2023-02-08T15:00:48,639 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2023-02-08T15:00:48,663 [INFO ] W-9001-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:48,663 [INFO ] W-9001-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:48,663 [INFO ] W-9001-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stderr
2023-02-08T15:00:48,663 [INFO ] W-9001-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stdout
2023-02-08T15:00:48,666 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:48,666 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-02-08T15:00:48,667 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:48,667 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:00:48,667 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:48,667 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:00:48,667 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:48,667 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:00:48,667 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:48,667 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:00:48,668 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:48,668 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:48,668 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:48,668 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:48,668 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2023-02-08T15:00:48,668 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2023-02-08T15:00:48,691 [INFO ] W-9000-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:48,691 [INFO ] W-9000-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:48,691 [INFO ] W-9000-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stdout
2023-02-08T15:00:48,691 [INFO ] W-9000-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stderr
2023-02-08T15:00:50,885 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:eirini-IdeaPad-3-15ALC6,timestamp:1675861250
2023-02-08T15:00:50,885 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:263.68517303466797|#Level:Host|#hostname:eirini-IdeaPad-3-15ALC6,timestamp:1675861250
2023-02-08T15:00:50,885 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:180.36685943603516|#Level:Host|#hostname:eirini-IdeaPad-3-15ALC6,timestamp:1675861250
2023-02-08T15:00:50,886 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:40.6|#Level:Host|#hostname:eirini-IdeaPad-3-15ALC6,timestamp:1675861250
2023-02-08T15:00:50,886 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:6216.5859375|#Level:Host|#hostname:eirini-IdeaPad-3-15ALC6,timestamp:1675861250
2023-02-08T15:00:50,886 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:7210.9375|#Level:Host|#hostname:eirini-IdeaPad-3-15ALC6,timestamp:1675861250
2023-02-08T15:00:50,886 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:55.1|#Level:Host|#hostname:eirini-IdeaPad-3-15ALC6,timestamp:1675861250
2023-02-08T15:00:50,909 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - --- Logging error ---
Traceback (most recent call last):
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/_common.py", line 443, in wrapper
    ret = self._cache[fun]
AttributeError: 'Process' object has no attribute '_cache'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/_pslinux.py", line 1645, in wrapper
    return fun(self, *args, **kwargs)
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/_common.py", line 446, in wrapper
    return fun(self)
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/_pslinux.py", line 1687, in _parse_stat_file
    data = bcat("%s/%s/stat" % (self._procfs_path, self.pid))
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/_common.py", line 776, in bcat
    return cat(fname, fallback=fallback, _open=open_binary)
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/_common.py", line 764, in cat
    with _open(fname) as f:
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/_common.py", line 728, in open_binary
    return open(fname, "rb", buffering=FILE_READ_BUFFER_SIZE)
FileNotFoundError: [Errno 2] No such file or directory: '/proc/595677/stat'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/__init__.py", line 361, in _init
    self.create_time()
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/__init__.py", line 714, in create_time
    self._create_time = self._proc.create_time()
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/_pslinux.py", line 1645, in wrapper
    return fun(self, *args, **kwargs)
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/_pslinux.py", line 1855, in create_time
    ctime = float(self._parse_stat_file()['create_time'])
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/_pslinux.py", line 1652, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: process no longer exists (pid=595677)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/metrics/process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/__init__.py", line 332, in __init__
    self._init(pid)
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/__init__.py", line 373, in _init
    raise NoSuchProcess(pid, msg='process PID not found')
psutil.NoSuchProcess: process PID not found (pid=595677)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/logging/__init__.py", line 1104, in emit
    self.flush()
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/logging/__init__.py", line 1084, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/metrics/metric_collector.py", line 29, in <module>
    check_process_mem_usage(sys.stdin)
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/metrics/process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('595677',)
--- Logging error ---
Traceback (most recent call last):
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/logging/__init__.py", line 1104, in emit
    self.flush()
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/logging/__init__.py", line 1084, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/metrics/metric_collector.py", line 29, in <module>
    check_process_mem_usage(sys.stdin)
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('595677', 0)
Exception ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='utf-8'>
BrokenPipeError: [Errno 32] Broken pipe

2023-02-08T15:00:50,909 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - --- Logging error ---
Traceback (most recent call last):
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/_common.py", line 443, in wrapper
    ret = self._cache[fun]
AttributeError: 'Process' object has no attribute '_cache'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/_pslinux.py", line 1645, in wrapper
    return fun(self, *args, **kwargs)
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/_common.py", line 446, in wrapper
    return fun(self)
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/_pslinux.py", line 1687, in _parse_stat_file
    data = bcat("%s/%s/stat" % (self._procfs_path, self.pid))
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/_common.py", line 776, in bcat
    return cat(fname, fallback=fallback, _open=open_binary)
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/_common.py", line 764, in cat
    with _open(fname) as f:
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/_common.py", line 728, in open_binary
    return open(fname, "rb", buffering=FILE_READ_BUFFER_SIZE)
FileNotFoundError: [Errno 2] No such file or directory: '/proc/595677/stat'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/__init__.py", line 361, in _init
    self.create_time()
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/__init__.py", line 714, in create_time
    self._create_time = self._proc.create_time()
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/_pslinux.py", line 1645, in wrapper
    return fun(self, *args, **kwargs)
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/_pslinux.py", line 1855, in create_time
    ctime = float(self._parse_stat_file()['create_time'])
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/_pslinux.py", line 1652, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: process no longer exists (pid=595677)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/metrics/process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/__init__.py", line 332, in __init__
    self._init(pid)
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/psutil/__init__.py", line 373, in _init
    raise NoSuchProcess(pid, msg='process PID not found')
psutil.NoSuchProcess: process PID not found (pid=595677)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/logging/__init__.py", line 1104, in emit
    self.flush()
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/logging/__init__.py", line 1084, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/metrics/metric_collector.py", line 29, in <module>
    check_process_mem_usage(sys.stdin)
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/metrics/process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('595677',)
--- Logging error ---
Traceback (most recent call last):
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/logging/__init__.py", line 1104, in emit
    self.flush()
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/logging/__init__.py", line 1084, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/metrics/metric_collector.py", line 29, in <module>
    check_process_mem_usage(sys.stdin)
  File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('595677', 0)
Exception ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='utf-8'>
BrokenPipeError: [Errno 32] Broken pipe

2023-02-08T15:01:09,641 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:01:09,641 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:01:09,668 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:01:09,668 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/bin/python, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2023-02-08T15:01:10,453 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-02-08T15:01:10,456 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Successfully loaded /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2023-02-08T15:01:10,456 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - [PID]595860
2023-02-08T15:01:10,457 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Torch worker started.
2023-02-08T15:01:10,457 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2023-02-08T15:01:10,457 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:01:10,457 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:01:10,457 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-02-08T15:01:10,457 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-02-08T15:01:10,458 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861270458
2023-02-08T15:01:10,458 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-02-08T15:01:10,458 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861270458
2023-02-08T15:01:10,459 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - model_name: roberta_intent, batchSize: 1
2023-02-08T15:01:10,492 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2023-02-08T15:01:10,496 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Successfully loaded /home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2023-02-08T15:01:10,496 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - [PID]595857
2023-02-08T15:01:10,496 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Torch worker started.
2023-02-08T15:01:10,496 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2023-02-08T15:01:10,496 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:01:10,496 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-02-08T15:01:10,496 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2023-02-08T15:01:10,496 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2023-02-08T15:01:10,497 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861270497
2023-02-08T15:01:10,497 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2023-02-08T15:01:10,497 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1675861270497
2023-02-08T15:01:10,498 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - model_name: roberta_intent, batchSize: 1
2023-02-08T15:01:10,628 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:01:10.628395: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
2023-02-08T15:01:10,628 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-08T15:01:10,663 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:01:10.663751: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
2023-02-08T15:01:10,664 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-08T15:01:11,262 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:01:11.261923: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:01:11,262 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:01:11.261970: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:01:11,262 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:01:11.261976: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-02-08T15:01:11,278 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:01:11.277876: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:01:11,278 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:01:11.277922: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-08T15:01:11,278 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - 2023-02-08 15:01:11.277928: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-02-08T15:01:12,413 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package wordnet to /home/eirini/nltk_data...
2023-02-08T15:01:12,413 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package wordnet to /home/eirini/nltk_data...
2023-02-08T15:01:12,428 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package wordnet is already up-to-date!
2023-02-08T15:01:12,428 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package wordnet is already up-to-date!
2023-02-08T15:01:12,428 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package omw-1.4 to /home/eirini/nltk_data...
2023-02-08T15:01:12,428 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data] Downloading package omw-1.4 to /home/eirini/nltk_data...
2023-02-08T15:01:12,464 [WARN ] W-9001-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package omw-1.4 is already up-to-date!
2023-02-08T15:01:12,464 [WARN ] W-9000-roberta_intent_1.0-stderr MODEL_LOG - [nltk_data]   Package omw-1.4 is already up-to-date!
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Backend worker process died.
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Backend worker process died.
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 100, in load
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 100, in load
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/handler.py", line 14, in <module>
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/handler.py", line 14, in <module>
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     from preprocessing_tools import PreProcessText
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     from preprocessing_tools import PreProcessText
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/preprocessing_tools.py", line 11, in <module>
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/tmp/models/2b1ba1f70cb84b758b0c2bfe518978c0/preprocessing_tools.py", line 11, in <module>
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     from sklearn.preprocessing import OneHotEncoder
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     from sklearn.preprocessing import OneHotEncoder
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'sklearn'
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'sklearn'
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - 
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-02-08T15:01:12,465 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     worker.run_server()
2023-02-08T15:01:12,465 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     worker.run_server()
2023-02-08T15:01:12,466 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-02-08T15:01:12,466 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-02-08T15:01:12,466 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-02-08T15:01:12,466 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-02-08T15:01:12,466 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-02-08T15:01:12,466 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-02-08T15:01:12,466 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-02-08T15:01:12,466 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-02-08T15:01:12,466 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-02-08T15:01:12,466 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-02-08T15:01:12,466 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-02-08T15:01:12,466 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-02-08T15:01:12,466 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 102, in load
2023-02-08T15:01:12,466 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 102, in load
2023-02-08T15:01:12,466 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2023-02-08T15:01:12,466 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2023-02-08T15:01:12,466 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 151, in _load_default_handler
2023-02-08T15:01:12,466 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/site-packages/ts/model_loader.py", line 151, in _load_default_handler
2023-02-08T15:01:12,466 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2023-02-08T15:01:12,466 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2023-02-08T15:01:12,466 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:01:12,466 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "/home/eirini/anaconda3/envs/Intent_Classification_AIDL123/lib/python3.10/importlib/__init__.py", line 126, in import_module
2023-02-08T15:01:12,466 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:01:12,466 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-02-08T15:01:12,466 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:01:12,466 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:01:12,466 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:01:12,466 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:01:12,466 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2023-02-08T15:01:12,466 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:01:12,466 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2023-02-08T15:01:12,466 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:01:12,466 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2023-02-08T15:01:12,466 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:01:12,466 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2023-02-08T15:01:12,466 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2023-02-08T15:01:12,466 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2023-02-08T15:01:12,466 [INFO ] W-9000-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handler'
2023-02-08T15:01:12,466 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2023-02-08T15:01:12,466 [INFO ] W-9001-roberta_intent_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handler'
2023-02-08T15:01:12,743 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-02-08T15:01:12,743 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-02-08T15:01:12,743 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:01:12,743 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:01:12,743 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2023-02-08T15:01:12,743 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2023-02-08T15:01:12,743 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:01:12,743 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-02-08T15:01:12,743 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:01:12,743 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:01:12,744 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:01:12,744 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:01:12,743 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:01:12,744 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:01:12,744 [DEBUG] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:01:12,743 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-02-08T15:01:12,744 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:01:12,744 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: roberta_intent, error: Worker died.
2023-02-08T15:01:12,744 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:01:12,744 [DEBUG] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-roberta_intent_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-02-08T15:01:12,744 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stderr
2023-02-08T15:01:12,744 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stderr
2023-02-08T15:01:12,744 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stdout
2023-02-08T15:01:12,744 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stderr
2023-02-08T15:01:12,744 [WARN ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-roberta_intent_1.0-stdout
2023-02-08T15:01:12,744 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stderr
2023-02-08T15:01:12,744 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stdout
2023-02-08T15:01:12,744 [WARN ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-roberta_intent_1.0-stdout
2023-02-08T15:01:12,744 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2023-02-08T15:01:12,744 [INFO ] W-9000-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2023-02-08T15:01:12,744 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 34 seconds.
2023-02-08T15:01:12,744 [INFO ] W-9001-roberta_intent_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 34 seconds.
2023-02-08T15:01:12,772 [INFO ] W-9001-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stderr
2023-02-08T15:01:12,772 [INFO ] W-9001-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stderr
2023-02-08T15:01:12,773 [INFO ] W-9001-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stdout
2023-02-08T15:01:12,773 [INFO ] W-9000-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stderr
2023-02-08T15:01:12,773 [INFO ] W-9000-roberta_intent_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stderr
2023-02-08T15:01:12,773 [INFO ] W-9001-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-roberta_intent_1.0-stdout
2023-02-08T15:01:12,773 [INFO ] W-9000-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stdout
2023-02-08T15:01:12,773 [INFO ] W-9000-roberta_intent_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-roberta_intent_1.0-stdout
